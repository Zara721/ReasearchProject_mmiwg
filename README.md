# Research project about Missing and Murdered Indigenous Women and Girls (MMIWG)

## Overview
Using data obtained from the GDELT project, specifically the Global Knowledge Graph (gkg) dataset, this project aims to study how MMIWG is represented in the news. By extracting and filtering data from the gkg that pertains to Canada and Indigenous people, I will analyze the resulting data and use various forms of data representation to identify different trends and truths about MMIWG.

## Coding Choices

### SQL Queries
When querying the data from the gkg, I used SQLite and made queries on tables of increasing size. When working on how to get the results I wanted from my query, I first looked at the document identifier (URLs) for entries that had Canada in the Counts, with the location being one of the simplest ways to filter. I also added that Counts should contain Indigenous as another basic filter. Although this kind of query brings a decent amount of results, the majority were not directly relevant to MMIWG, so I looked through the documentation to find a way to increase the relevant results that the query brought. The addition of KILL in counts or Murder in all names helped with the search results because KILL in Counts means that GDELT's algorithm picked up on an individual being killed in the article, while Murder in all names also made sure articles that directly use 'Murdered Indigenous Women' would be included. I also included First Nation in all names or themes like INDIGENOUS to make the people being discussed more likely to be Indigenous.

In addition to inclusive filters, I excluded results that had covid or corona in the document identifier (URL), which would mean that the article content will discuss COVID-19. To further avoid this, I also removed articles that had them PANDEMIC and CORONAVIRUS. However, the downside is that some relevant articles that may include previews or links to other articles that discussed the pandemic would also be removed. Still, the percentage is negligible compared to the number of articles it removes, just about the pandemic. The reason I specifically tried to filter out this event is that because COVID was a disease that killed people, my other filters led to a lot of articles simply being about COVID-19, which is not what this research project is about. When excluding topics, I also filtered for results that did not contain pipeline since a decent amount of the results that came up were about the oil pipeline running through Indigenous lands.

The last part of my query is filtering, excluding results whose themes start with EDUCATION, GENERAL GOVERNMENT, GENERAL HEALTH, MANMADE DISASTER IMPLIED, and TAX_DISEASES. I chose to do this because after grouping by theme, I found that articles were generally about the first theme that showed in their list of themes, so filtering to exclude results that start with themes unrelated to MMIWG reduced the amount of non-relevant results. Although other non-relevant themes showed up, I chose to filter against only the ones that showed up the most to be on the safer side.

### Data Clustering
After having the data from my SQL query, about half the results were simply not related to MMIWG, so to further clean the data, I used k-means clustering on 711 from a subset of the gkg database that had 100000 rows. The data I used for the clustering was a table with the article_urls as ids and each unique theme as a header; then, for each article, if that theme appeared in the article, it would have a 1 and if not, it would be a 0. After using the elbow method to get an optimal k value of 7, the resulting clusters have definitely made it easier to identify non-relevant articles, with there being a tendency for articles that are about other general topics to be in a cluster with no relevant MMIWG, while some clusters have a mix of MMIWG and non-MMIWG related articles.

### Refining Query
After getting the data clusters, I identified which articles were often grouped with MMIWG-related topics and refined my query to exclude those topics. This method also led to the query excluding the themes SUICIDE, MENTAL HEALTH and ILLEGAL DRUGS, which reduced the data by about 20%. Although the clustering using themes worked well, I also made clusters around Counts and AllNames to check whether there was a better method. Ultimately, AllNames was unsuitable for clustering, with around 90% of the data being repeatedly grouped into one cluster. By contrast, Counts (after removing numbers) could cluster the data quite well.

### More Data Filtering
I used the refined query on a database with 1.8 million entries and received 30,000 results. From there, I spent hours reviewing the data and identifying leading themes associated with non-relevant entries. After this filtering, ~10,000 entries were removed, and I was left with around ~20,000 entries. Given that a significant percent of entries still wasn't relevant, I made a query on the subset of data I had that filtered using keywords in the AllNames, importing the results to another database I had ~2,000, then after removing duplicates through looking at each URL I was left with 1703 articles that were basically all relevant to MMIWG. To ensure I hadn't left too many relevant articles in the previous database, sampling was done by going through 150 randomly chosen articles from the ~10,000 entries. In the end, only 11 were related to MMIWG, so about 7% of the data, meaning that my filtering was sufficient.

### Web Scraping
With 1703 article URLs, next, I made a program to retrieve the title and body text from each URL using Playwright and asyncio. The program first goes through my URL list and attempts to access each URL; since I used asynchronous code for efficiency, I also had to use a semaphore to limit the concurrent tasks to prevent my program from freezing. On the first pass through the URLs, if the program can't access the URL for any reason, it gets added to a list. If the request received has a bad response status, it gets added to a different list. For URLs that were successfully accessed, the URL, title, and body are stored in a JSON file. After this, the code goes through each URL in the could_not_access list and tries to access them again. 

To ensure this code would work before running it on all 1703 URLs, I did some tests with 50 and 100 URLs, changing the number of threads to find a balance between faster times and how much my computer could handle. This process resulted in me using a limit of 15 concurrent tasks when running the program on the full url list. However, the program only accessed ~25% of the URLs during the first run. To rectify this, I changed the timeout from 30 seconds to 60 seconds; this proved to be effective as on the program's second run, ~50% of the URLs ended up being successfully accessed, with another ~25% being bad requests, and the last ~25% not being able to be accessed.

### Accessible Visualizations
I made a dashboard with different data visualizations for a better overview of the articles in my database. I made a bar chart that showed the distribution of article counts over the years. I made other bar charts to show the top themes across the different articles, with the themes sourced from the GDELT database. I also made a chart to show the top domain names of the articles about MMIWG. Furthermore, I made a word cloud using all the articles' title text, body text and another one for all the AllNames from the different articles. There is also a table of the current articles in my database, with the date the article was published, the article link and the title of the webpage that had been retrieved.
<b>Dashboard Link:</b> https://zara721.github.io/MMIWG-Dashboard/index.html

### Updating Database
After a lack of articles from a website in my database was pointed out, I went back to review my queries for any blind spots. I made a table with all the information about the Tina Fontaine events, and just looking at the results makes it clear that the main reason that my query did not pick most of these up is that only 936 had a Counts like KILL which was a key filter, and 1586 had a Counts column that is simply blank. Those two numbers accounted for 86% of the Tina Fontaine articles, so for the entries that do have Counts recorded, 70% of those do contain the term "KILL", while the remaining 30% use terms like ARREST, SEIZE, effect, KIDNAP, PROTEST, WOUND.

I then checked whether the ethnicity keywords were working correctly, and 97% of the articles did contain some version of my filter for Indigenous. The leading themes I chose to exclude would not have excluded more than 5% of the Tina Fontaine articles. However, 88 of Tina Fontaine's articles had Themes that were also blank. Although that is only 3% of articles, it still feels important to note.

So, upon review, I found that the most significant factor that went awry in my filtering process was my use of the Counts column, as I was unaware that such a substantial number of articles have blank Counts. After using this information along with a list of keywords, I made a new table that increased my entries from 1703 to 4613, with 3087 of those articles also having the title and body text retrieved and stored in the table.


### Helpful Links
* https://www.gdeltproject.org/
* https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/
* http://data.gdeltproject.org/documentation/GDELT-Event_Codebook-V2.0.pdf
* http://data.gdeltproject.org/documentation/GDELT-Global_Knowledge_Graph_Codebook-V2.1.pdf
